{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM Betting Strategy - Training Workflow\n",
        "\n",
        "This notebook demonstrates the complete workflow for building an LSTM-based betting strategy using time-series odds data.\n",
        "\n",
        "## Overview\n",
        "\n",
        "We'll build a recurrent neural network that predicts win probability for NBA games using:\n",
        "- **Time-series odds sequences** (72 hours of historical data sampled every 3 hours)\n",
        "- **Line movement patterns** over time\n",
        "- **Sharp vs retail odds discrepancies** evolution\n",
        "- **Market dynamics** (bookmaker consensus, volatility)\n",
        "\n",
        "The trained LSTM integrates seamlessly with the backtesting framework via `BetOpportunity.confidence`.\n",
        "\n",
        "## Architecture\n",
        "\n",
        "- **Input**: Historical odds sequences (batch_size, timesteps=24, features=14)\n",
        "- **Model**: 2-layer LSTM → Fully Connected → Sigmoid activation\n",
        "- **Output**: Win probability (0-1)\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Ensure dependencies are installed:\n",
        "```bash\n",
        "uv add torch numpy matplotlib seaborn scikit-learn\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Project imports\n",
        "from odds_analytics.backtesting import (\n",
        "    BacktestConfig,\n",
        "    BacktestEngine,\n",
        "    BetConstraintsConfig,\n",
        "    BetSizingConfig,\n",
        ")\n",
        "from odds_analytics.feature_extraction import SequenceFeatureExtractor\n",
        "from odds_analytics.lstm_strategy import LSTMModel, LSTMStrategy\n",
        "from odds_analytics.sequence_loader import (\n",
        "    load_sequences_for_event,\n",
        "    prepare_lstm_training_data,\n",
        ")\n",
        "from odds_core.config import Settings\n",
        "from odds_core.database import async_session_maker\n",
        "from odds_core.models import EventStatus\n",
        "from odds_lambda.storage.readers import OddsReader\n",
        "\n",
        "# Configure plotting\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load settings\n",
        "settings = Settings()\n",
        "\n",
        "print(\"✓ Imports successful\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preparation\n",
        "\n",
        "Load historical events with final scores and prepare time-series sequences for LSTM training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure training period\n",
        "TRAIN_START = datetime(2025, 10, 23)\n",
        "TRAIN_END = datetime(2025, 10, 31)\n",
        "\n",
        "# LSTM hyperparameters\n",
        "LOOKBACK_HOURS = 72  # Use 72 hours of historical data\n",
        "TIMESTEPS = 24  # Sample every 3 hours (72/3 = 24 timesteps)\n",
        "MARKET = \"h2h\"  # Focus on moneyline market\n",
        "\n",
        "print(f\"Loading events from {TRAIN_START.date()} to {TRAIN_END.date()}...\")\n",
        "print(f\"Sequence configuration: {LOOKBACK_HOURS}h lookback, {TIMESTEPS} timesteps\")\n",
        "\n",
        "async with async_session_maker() as session:\n",
        "    reader = OddsReader(session)\n",
        "    \n",
        "    # Get completed events\n",
        "    events = await reader.get_events_by_date_range(\n",
        "        start_date=TRAIN_START,\n",
        "        end_date=TRAIN_END,\n",
        "        status=EventStatus.FINAL\n",
        "    )\n",
        "    \n",
        "    print(f\"Found {len(events)} completed events\")\n",
        "    \n",
        "    # Prepare LSTM training data\n",
        "    # This creates sequences for both home and away teams\n",
        "    X_home, y_home, masks_home = await prepare_lstm_training_data(\n",
        "        events=events,\n",
        "        session=session,\n",
        "        market=MARKET,\n",
        "        outcome=\"home\",\n",
        "        lookback_hours=LOOKBACK_HOURS,\n",
        "        timesteps=TIMESTEPS,\n",
        "    )\n",
        "    \n",
        "    X_away, y_away, masks_away = await prepare_lstm_training_data(\n",
        "        events=events,\n",
        "        session=session,\n",
        "        market=MARKET,\n",
        "        outcome=\"away\",\n",
        "        lookback_hours=LOOKBACK_HOURS,\n",
        "        timesteps=TIMESTEPS,\n",
        "    )\n",
        "\n",
        "# Combine home and away samples\n",
        "X = np.concatenate([X_home, X_away], axis=0)\n",
        "y = np.concatenate([y_home, y_away], axis=0)\n",
        "masks = np.concatenate([masks_home, masks_away], axis=0)\n",
        "\n",
        "print(f\"\\nDataset shape: X={X.shape}, y={y.shape}, masks={masks.shape}\")\n",
        "print(f\"Features per timestep: {X.shape[2]}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "print(f\"Win rate: {y.mean():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Overview\n",
        "\n",
        "The `SequenceFeatureExtractor` creates **14 features per timestep**:\n",
        "\n",
        "**Basic Odds Features**:\n",
        "1. `american_odds` - Raw American odds\n",
        "2. `decimal_odds` - Decimal odds\n",
        "3. `implied_prob` - Market implied probability\n",
        "\n",
        "**Line Movement**:\n",
        "4. `odds_change_from_prev` - Change from previous timestep\n",
        "5. `odds_change_from_opening` - Change from opening line\n",
        "6. `prob_change_from_prev` - Probability change from previous\n",
        "7. `prob_change_from_opening` - Probability change from opening\n",
        "\n",
        "**Market Context**:\n",
        "8. `num_bookmakers` - Number of bookmakers offering odds\n",
        "9. `odds_std` - Standard deviation across bookmakers\n",
        "\n",
        "**Sharp vs Retail**:\n",
        "10. `sharp_odds` - Pinnacle/Circa odds (sharp bookmakers)\n",
        "11. `sharp_prob` - Sharp implied probability\n",
        "12. `retail_sharp_diff` - Retail vs sharp discrepancy\n",
        "\n",
        "**Time Features**:\n",
        "13. `hours_to_game` - Hours until game start\n",
        "14. `time_of_day_sin` - Cyclical time encoding (sine)\n",
        "15. `time_of_day_cos` - Cyclical time encoding (cosine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize a sample sequence\n",
        "sample_idx = 0\n",
        "sample_sequence = X[sample_idx]\n",
        "sample_mask = masks[sample_idx]\n",
        "sample_label = y[sample_idx]\n",
        "\n",
        "# Get valid timesteps (where mask=1)\n",
        "valid_steps = np.where(sample_mask == 1)[0]\n",
        "\n",
        "# Plot key features over time\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Implied probability evolution\n",
        "axes[0].plot(valid_steps, sample_sequence[valid_steps, 2], marker='o', linewidth=2, label='Implied Prob')\n",
        "axes[0].axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='50% Line')\n",
        "axes[0].set_ylabel('Probability')\n",
        "axes[0].set_title(f'Sample Sequence (Label: {\"Win\" if sample_label == 1 else \"Loss\"})')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Sharp vs Retail\n",
        "axes[1].plot(valid_steps, sample_sequence[valid_steps, 10], marker='s', linewidth=2, label='Sharp Prob')\n",
        "axes[1].plot(valid_steps, sample_sequence[valid_steps, 2], marker='o', linewidth=2, alpha=0.5, label='Market Prob')\n",
        "axes[1].set_ylabel('Probability')\n",
        "axes[1].set_title('Sharp vs Market Probability')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Hours to game\n",
        "axes[2].plot(valid_steps, sample_sequence[valid_steps, 12], marker='x', linewidth=2, color='green')\n",
        "axes[2].set_xlabel('Timestep')\n",
        "axes[2].set_ylabel('Hours to Game')\n",
        "axes[2].set_title('Time Until Game Start')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nSample sequence details:\")\n",
        "print(f\"  Valid timesteps: {len(valid_steps)}/{TIMESTEPS}\")\n",
        "print(f\"  Label: {'Win' if sample_label == 1 else 'Loss'}\")\n",
        "print(f\"  Final implied prob: {sample_sequence[valid_steps[-1], 2]:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train/Test Split\n",
        "\n",
        "Split data for training and evaluation. Note: For production, consider time-series split (walk-forward analysis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data (80/20 train/test)\n",
        "# Note: Using stratified random split for simplicity\n",
        "# For production, consider time-based split to prevent lookahead bias\n",
        "X_train, X_test, y_train, y_test, masks_train, masks_test = train_test_split(\n",
        "    X, y, masks,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\nTraining win rate: {y_train.mean():.2%}\")\n",
        "print(f\"Test win rate: {y_test.mean():.2%}\")\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.FloatTensor(y_train)\n",
        "masks_train_tensor = torch.FloatTensor(masks_train)\n",
        "\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "y_test_tensor = torch.FloatTensor(y_test)\n",
        "masks_test_tensor = torch.FloatTensor(masks_test)\n",
        "\n",
        "print(\"\\n✓ Data converted to PyTorch tensors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Training\n",
        "\n",
        "Train LSTM model using the LSTMStrategy class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize LSTM strategy\n",
        "strategy = LSTMStrategy(\n",
        "    lookback_hours=LOOKBACK_HOURS,\n",
        "    timesteps=TIMESTEPS,\n",
        "    hidden_size=64,\n",
        "    num_layers=2,\n",
        "    dropout=0.2,\n",
        "    market=MARKET,\n",
        "    min_edge_threshold=0.03,  # 3% minimum edge to bet\n",
        "    min_confidence=0.52,  # 52% minimum model probability\n",
        ")\n",
        "\n",
        "print(\"LSTM Architecture:\")\n",
        "print(f\"  Input size: {X.shape[2]} features\")\n",
        "print(f\"  Hidden size: {strategy.hidden_size}\")\n",
        "print(f\"  Number of layers: {strategy.num_layers}\")\n",
        "print(f\"  Dropout: {strategy.dropout}\")\n",
        "print(f\"  Total parameters: {sum(p.numel() for p in strategy.model.parameters()):,}\")\n",
        "\n",
        "# Training configuration\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "print(f\"\\nTraining configuration:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting training...\")\n",
        "\n",
        "# Prepare data for training\n",
        "# Convert events back to BacktestEvent format for training\n",
        "async with async_session_maker() as session:\n",
        "    reader = OddsReader(session)\n",
        "    events_for_training = await reader.get_events_by_date_range(\n",
        "        start_date=TRAIN_START,\n",
        "        end_date=TRAIN_END,\n",
        "        status=EventStatus.FINAL\n",
        "    )\n",
        "\n",
        "history = await strategy.train(\n",
        "    events=events_for_training,\n",
        "    session=session,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    outcome=\"home\"  # Train on home team outcomes\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history['loss'], linewidth=2, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (BCE)')\n",
        "plt.title('LSTM Training Loss Over Time')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final training loss: {history['loss'][-1]:.4f}\")\n",
        "print(f\"Initial loss: {history['loss'][0]:.4f}\")\n",
        "print(f\"Loss reduction: {((history['loss'][0] - history['loss'][-1]) / history['loss'][0] * 100):.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Evaluation\n",
        "\n",
        "Evaluate model performance on held-out test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "strategy.model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = strategy.model(X_test_tensor, masks_test_tensor)\n",
        "    y_pred_proba = test_outputs.numpy()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"Model Performance on Test Set:\")\n",
        "print(f\"  Accuracy: {accuracy:.2%}\")\n",
        "print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Loss\", \"Win\"]))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Loss', 'Win'], yticklabels=['Loss', 'Win'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - LSTM Model')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, linewidth=2, label=f'LSTM (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - LSTM Model')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calibration Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot calibration curve\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(prob_pred, prob_true, marker='o', linewidth=2, label='LSTM')\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Perfect Calibration')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Actual Win Rate')\n",
        "plt.title('Calibration Plot - LSTM Model')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNote: A well-calibrated model has predictions close to the diagonal line.\")\n",
        "print(\"If the model is consistently below the line, it's underconfident.\")\n",
        "print(\"If the model is consistently above the line, it's overconfident.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prediction Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze prediction distribution\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Subplot 1: Overall distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(y_pred_proba, bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(x=0.5, color='r', linestyle='--', label='Decision Threshold')\n",
        "plt.axvline(x=0.52, color='g', linestyle='--', label='Betting Threshold (min_confidence)')\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Predicted Probabilities')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Subplot 2: By actual outcome\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(y_pred_proba[y_test == 0], bins=15, alpha=0.5, label='Actual Loss', edgecolor='black')\n",
        "plt.hist(y_pred_proba[y_test == 1], bins=15, alpha=0.5, label='Actual Win', edgecolor='black')\n",
        "plt.axvline(x=0.5, color='r', linestyle='--', alpha=0.5)\n",
        "plt.xlabel('Predicted Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Predictions by Actual Outcome')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistics\n",
        "print(\"Prediction Statistics:\")\n",
        "print(f\"  Mean predicted probability: {y_pred_proba.mean():.4f}\")\n",
        "print(f\"  Std of predictions: {y_pred_proba.std():.4f}\")\n",
        "print(f\"  Min prediction: {y_pred_proba.min():.4f}\")\n",
        "print(f\"  Max prediction: {y_pred_proba.max():.4f}\")\n",
        "print(f\"\\n  Predictions > 52% (would bet): {(y_pred_proba > 0.52).sum()} / {len(y_pred_proba)} ({(y_pred_proba > 0.52).mean():.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save Model\n",
        "\n",
        "Save the trained LSTM model for use in backtesting and production."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "models_dir = Path(\"models\")\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save model\n",
        "model_path = models_dir / \"lstm_h2h_v1.pth\"\n",
        "strategy.save_model(str(model_path))\n",
        "\n",
        "print(f\"✓ Model saved to {model_path}\")\n",
        "print(\"\\nModel details:\")\n",
        "print(f\"  Timesteps: {TIMESTEPS}\")\n",
        "print(f\"  Features per timestep: {X.shape[2]}\")\n",
        "print(f\"  Hidden size: {strategy.hidden_size}\")\n",
        "print(f\"  Layers: {strategy.num_layers}\")\n",
        "print(f\"  Training samples: {X_train.shape[0]}\")\n",
        "print(f\"  Test ROC-AUC: {roc_auc:.4f}\")\n",
        "print(f\"  Test Accuracy: {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Backtest the Strategy\n",
        "\n",
        "Test the trained LSTM model on a separate time period using the backtesting framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define backtest period (should be different from training period)\n",
        "BACKTEST_START = TRAIN_END + timedelta(days=1)\n",
        "BACKTEST_END = BACKTEST_START + timedelta(days=7)\n",
        "\n",
        "# Load the saved model\n",
        "backtest_strategy = LSTMStrategy(\n",
        "    model_path=str(model_path),\n",
        "    lookback_hours=LOOKBACK_HOURS,\n",
        "    timesteps=TIMESTEPS,\n",
        "    hidden_size=64,\n",
        "    num_layers=2,\n",
        "    dropout=0.2,\n",
        "    market=MARKET,\n",
        "    min_edge_threshold=0.03,  # Require 3% edge\n",
        "    min_confidence=0.52,  # Only bet if model predicts >52% win probability\n",
        ")\n",
        "\n",
        "# Configure backtest with nested config objects\n",
        "config = BacktestConfig(\n",
        "    start_date=BACKTEST_START,\n",
        "    end_date=BACKTEST_END,\n",
        "    initial_bankroll=10000.0,\n",
        "    decision_hours_before_game=1.0,\n",
        "    sizing=BetSizingConfig(\n",
        "        method=\"fractional_kelly\",\n",
        "        kelly_fraction=0.25,  # Quarter-Kelly for safety\n",
        "    ),\n",
        "    constraints=BetConstraintsConfig(\n",
        "        min_bet_size=10.0,\n",
        "        max_bet_size=500.0,\n",
        "        max_bet_percentage=0.05\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(f\"Running backtest from {BACKTEST_START.date()} to {BACKTEST_END.date()}...\")\n",
        "\n",
        "# Run backtest\n",
        "async with async_session_maker() as session:\n",
        "    reader = OddsReader(session)\n",
        "    engine = BacktestEngine(backtest_strategy, config, reader)\n",
        "    result = await engine.run()\n",
        "\n",
        "print(\"\\n✓ Backtest complete\")\n",
        "print(result.to_summary_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyze Backtest Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "result.to_json(\"backtest_results_lstm.json\")\n",
        "result.to_csv(\"backtest_bets_lstm.csv\")\n",
        "\n",
        "print(\"✓ Results saved\")\n",
        "print(\"  JSON: backtest_results_lstm.json\")\n",
        "print(\"  CSV: backtest_bets_lstm.csv\")\n",
        "\n",
        "# Plot equity curve\n",
        "import pandas as pd\n",
        "\n",
        "equity_df = pd.DataFrame([\n",
        "    {\"date\": point.date, \"bankroll\": point.bankroll}\n",
        "    for point in result.equity_curve\n",
        "])\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(equity_df[\"date\"], equity_df[\"bankroll\"], linewidth=2, label='Bankroll')\n",
        "plt.axhline(\n",
        "    y=config.initial_bankroll,\n",
        "    color='r',\n",
        "    linestyle='--',\n",
        "    alpha=0.5,\n",
        "    label='Starting Bankroll'\n",
        ")\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Bankroll ($)')\n",
        "plt.title('LSTM Strategy - Equity Curve')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Metrics:\")\n",
        "print(f\"  Total Bets: {result.total_bets}\")\n",
        "print(f\"  Win Rate: {result.win_rate:.2f}%\")\n",
        "print(f\"  ROI: {result.roi:.2f}%\")\n",
        "print(f\"  Total Profit: ${result.total_profit:,.2f}\")\n",
        "print(f\"  Sharpe Ratio: {result.sharpe_ratio:.2f}\")\n",
        "print(f\"  Max Drawdown: ${abs(result.max_drawdown):,.2f} ({result.max_drawdown_percentage:.2f}%)\")\n",
        "\n",
        "if result.profit_factor:\n",
        "    print(f\"  Profit Factor: {result.profit_factor:.2f}\")\n",
        "if result.calmar_ratio:\n",
        "    print(f\"  Calmar Ratio: {result.calmar_ratio:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bet Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze bets by confidence level\n",
        "if result.bet_records:\n",
        "    bets_df = pd.DataFrame([vars(bet) for bet in result.bet_records])\n",
        "    \n",
        "    # Group by confidence bins\n",
        "    bets_df['confidence_bin'] = pd.cut(bets_df['confidence'], bins=[0.5, 0.55, 0.6, 0.65, 1.0], \n",
        "                                        labels=['50-55%', '55-60%', '60-65%', '65%+'])\n",
        "    \n",
        "    confidence_analysis = bets_df.groupby('confidence_bin').agg({\n",
        "        'event_id': 'count',\n",
        "        'result': lambda x: (x == 'win').mean() * 100,\n",
        "        'profit': 'sum',\n",
        "        'stake': 'mean'\n",
        "    }).round(2)\n",
        "    \n",
        "    confidence_analysis.columns = ['Count', 'Win Rate (%)', 'Total Profit ($)', 'Avg Stake ($)']\n",
        "    \n",
        "    print(\"\\nPerformance by Confidence Level:\")\n",
        "    print(confidence_analysis)\n",
        "    \n",
        "    # Plot confidence vs actual performance\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    plt.subplot(1, 2, 1)\n",
        "    confidence_analysis['Win Rate (%)'].plot(kind='bar', color='steelblue', edgecolor='black')\n",
        "    plt.axhline(y=52.38, color='r', linestyle='--', label='Breakeven (52.38%)')\n",
        "    plt.ylabel('Win Rate (%)')\n",
        "    plt.title('Win Rate by Confidence Level')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    confidence_analysis['Total Profit ($)'].plot(kind='bar', color='green', edgecolor='black')\n",
        "    plt.axhline(y=0, color='r', linestyle='-', linewidth=1)\n",
        "    plt.ylabel('Total Profit ($)')\n",
        "    plt.title('Profit by Confidence Level')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nNo bets placed during backtest period.\")\n",
        "    print(\"Consider:\")\n",
        "    print(\"  - Lowering min_confidence threshold\")\n",
        "    print(\"  - Lowering min_edge_threshold\")\n",
        "    print(\"  - Extending backtest period\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Data Preparation**: Loading historical events with time-series odds sequences\n",
        "2. **Feature Engineering**: 14 features per timestep capturing line movement, sharp vs retail, and market dynamics\n",
        "3. **Model Training**: 2-layer LSTM with dropout for binary win/loss prediction\n",
        "4. **Evaluation**: ROC-AUC, calibration analysis, prediction distribution\n",
        "5. **Backtesting**: Seamless integration with backtesting framework using Kelly Criterion sizing\n",
        "\n",
        "### Key Insights\n",
        "\n",
        "**LSTM Advantages**:\n",
        "- Captures **temporal patterns** in line movement\n",
        "- Learns **sequential dependencies** (e.g., steam moves, reverse line movement)\n",
        "- Handles **variable-length sequences** via attention masks\n",
        "- Naturally incorporates **time-until-game** dynamics\n",
        "\n",
        "**Compared to XGBoost**:\n",
        "- **XGBoost**: Better for tabular features, interpretable, faster training\n",
        "- **LSTM**: Better for sequential patterns, handles time-series naturally, requires more data\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "**Model Improvements**:\n",
        "1. **Attention Mechanism**: Add attention layers to focus on critical timesteps (e.g., closing line)\n",
        "2. **Bidirectional LSTM**: Process sequences forward and backward\n",
        "3. **Multi-Task Learning**: Predict both winner and margin of victory\n",
        "4. **Ensemble**: Combine LSTM with XGBoost for robust predictions\n",
        "\n",
        "**Feature Engineering**:\n",
        "1. **Team Features**: Recent form, injuries, rest days, travel distance\n",
        "2. **Matchup Features**: Head-to-head history, pace metrics, defensive ratings\n",
        "3. **Advanced Line Movement**: Volume-weighted odds, steam detection, reverse line movement flags\n",
        "\n",
        "**Training Enhancements**:\n",
        "1. **Walk-Forward Validation**: Time-series cross-validation\n",
        "2. **Hyperparameter Tuning**: Grid search for hidden_size, num_layers, dropout\n",
        "3. **Learning Rate Scheduling**: Decay learning rate over epochs\n",
        "4. **Early Stopping**: Monitor validation loss to prevent overfitting\n",
        "\n",
        "**Production Deployment**:\n",
        "1. **Real-Time Inference**: Integrate with live odds fetching\n",
        "2. **Model Versioning**: Track model performance over time\n",
        "3. **A/B Testing**: Compare multiple model versions in production\n",
        "4. **Monitoring**: Track prediction calibration and bet performance\n",
        "\n",
        "### Resources\n",
        "\n",
        "- **LSTM Implementation**: `packages/odds-analytics/odds_analytics/lstm_strategy.py`\n",
        "- **Feature Extraction**: `packages/odds-analytics/odds_analytics/feature_extraction.py`\n",
        "- **Sequence Loading**: `packages/odds-analytics/odds_analytics/sequence_loader.py`\n",
        "- **Backtesting Guide**: `BACKTESTING_GUIDE.md`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
