{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost ML Betting Strategy - Training Workflow\n",
    "\n",
    "This notebook demonstrates the complete workflow for building an ML-based betting strategy using XGBoost.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll build a binary classifier that predicts win probability for NBA games using:\n",
    "- Historical odds data from multiple bookmakers\n",
    "- Line movement patterns\n",
    "- Sharp vs retail odds discrepancies\n",
    "- Market consensus and efficiency metrics\n",
    "\n",
    "The trained model integrates seamlessly with the backtesting framework via `BetOpportunity.confidence`.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Ensure dependencies are installed:\n",
    "```bash\n",
    "uv add xgboost scikit-learn numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Project imports\n",
    "from analytics.backtesting import BacktestConfig, BacktestEngine\n",
    "from analytics.backtesting.models import BacktestEvent\n",
    "from analytics.ml_strategy_example import FeatureEngineering, XGBoostStrategy\n",
    "from core.config import Settings\n",
    "from core.database import get_async_session\n",
    "from core.models import EventStatus\n",
    "from storage.readers import OddsReader\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Load settings\n",
    "settings = Settings()\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Load historical events with final scores and their corresponding odds snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def load_training_data(\n",
    "    start_date: datetime,\n",
    "    end_date: datetime,\n",
    "    decision_hours_before: int = 1\n",
    ") -> tuple[list[BacktestEvent], list[list]]:\n",
    "    \"\"\"\n",
    "    Load historical events and their odds snapshots for training.\n",
    "    \n",
    "    Args:\n",
    "        start_date: Start of training period\n",
    "        end_date: End of training period\n",
    "        decision_hours_before: Hours before game to get odds (default: 1)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (events, odds_snapshots)\n",
    "    \"\"\"\n",
    "    async with get_async_session() as session:\n",
    "        reader = OddsReader(session)\n",
    "        \n",
    "        # Get completed events with scores\n",
    "        events = await reader.get_events_by_date_range(\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            status=EventStatus.FINAL\n",
    "        )\n",
    "        \n",
    "        print(f\"Found {len(events)} completed events\")\n",
    "        \n",
    "        # Convert to BacktestEvent and get odds\n",
    "        backtest_events = []\n",
    "        odds_snapshots = []\n",
    "        \n",
    "        for event in events:\n",
    "            bt_event = BacktestEvent.from_db_event(event)\n",
    "            if bt_event is None:\n",
    "                continue\n",
    "            \n",
    "            # Get odds at decision time\n",
    "            decision_time = event.commence_time - timedelta(hours=decision_hours_before)\n",
    "            odds = await reader.get_odds_at_time(\n",
    "                event.id,\n",
    "                decision_time,\n",
    "                tolerance_minutes=30\n",
    "            )\n",
    "            \n",
    "            if odds:\n",
    "                backtest_events.append(bt_event)\n",
    "                odds_snapshots.append(odds)\n",
    "        \n",
    "        print(f\"Loaded {len(backtest_events)} events with odds data\")\n",
    "        \n",
    "        return backtest_events, odds_snapshots\n",
    "\n",
    "# Load data for training period (adjust dates based on your data)\n",
    "TRAIN_START = datetime(2024, 10, 1)\n",
    "TRAIN_END = datetime(2024, 11, 30)\n",
    "\n",
    "events, odds_snapshots = await load_training_data(TRAIN_START, TRAIN_END)\n",
    "\n",
    "print(f\"\\nTraining data: {len(events)} games from {TRAIN_START.date()} to {TRAIN_END.date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Extract features from each event and create training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_dataset(\n",
    "    events: list[BacktestEvent],\n",
    "    odds_snapshots: list[list],\n",
    "    market: str = \"h2h\"\n",
    ") -> tuple[pd.DataFrame, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Create training dataset from events and odds.\n",
    "    \n",
    "    For each game, we create two samples:\n",
    "    - Home team sample (label=1 if home won, 0 otherwise)\n",
    "    - Away team sample (label=1 if away won, 0 otherwise)\n",
    "    \n",
    "    Args:\n",
    "        events: List of completed events\n",
    "        odds_snapshots: Corresponding odds snapshots\n",
    "        market: Market to analyze (h2h, spreads, totals)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (features_df, labels_array)\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    labels = []\n",
    "    \n",
    "    for event, odds in zip(events, odds_snapshots):\n",
    "        # Home team sample\n",
    "        home_features = FeatureEngineering.extract_features(\n",
    "            event, odds, market=market, outcome=event.home_team\n",
    "        )\n",
    "        \n",
    "        if home_features:\n",
    "            samples.append(home_features)\n",
    "            # Label: 1 if home won, 0 otherwise\n",
    "            labels.append(1 if event.home_score > event.away_score else 0)\n",
    "        \n",
    "        # Away team sample\n",
    "        away_features = FeatureEngineering.extract_features(\n",
    "            event, odds, market=market, outcome=event.away_team\n",
    "        )\n",
    "        \n",
    "        if away_features:\n",
    "            samples.append(away_features)\n",
    "            # Label: 1 if away won, 0 otherwise\n",
    "            labels.append(1 if event.away_score > event.home_score else 0)\n",
    "    \n",
    "    # Convert to DataFrame and array\n",
    "    features_df = pd.DataFrame(samples)\n",
    "    labels_array = np.array(labels)\n",
    "    \n",
    "    return features_df, labels_array\n",
    "\n",
    "# Create training dataset\n",
    "features_df, labels = create_training_dataset(events, odds_snapshots)\n",
    "\n",
    "print(f\"Dataset shape: {features_df.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(labels)}\")\n",
    "print(f\"Win rate: {labels.mean():.2%}\\n\")\n",
    "\n",
    "# Display sample of features\n",
    "print(\"Feature names:\")\n",
    "for i, col in enumerate(features_df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nFirst sample features:\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "Split data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80/20 train/test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_df.values,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining win rate: {y_train.mean():.2%}\")\n",
    "print(f\"Test win rate: {y_test.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Train XGBoost classifier with default parameters first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train initial model with default parameters\n",
    "strategy = XGBoostStrategy()\n",
    "\n",
    "strategy.train(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    feature_names=list(features_df.columns),\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"✓ Model trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Evaluate model performance on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = strategy.model.predict(X_test)\n",
    "y_pred_proba = strategy.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"  Accuracy: {accuracy:.2%}\")\n",
    "print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Loss\", \"Win\"]))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f\"XGBoost (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", linewidth=1, label=\"Random Classifier\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot calibration (predicted probability vs actual win rate)\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_pred_proba, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\", linewidth=2, label=\"XGBoost\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", linewidth=1, label=\"Perfect Calibration\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Actual Win Rate\")\n",
    "plt.title(\"Calibration Plot (Reliability Curve)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: A well-calibrated model has predictions close to the diagonal line.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "Analyze which features are most important for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = strategy.get_feature_importance()\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": list(feature_importance.keys()),\n",
    "    \"Importance\": list(feature_importance.values())\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "# Plot top 15 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = importance_df.head(15)\n",
    "plt.barh(range(len(top_features)), top_features[\"Importance\"])\n",
    "plt.yticks(range(len(top_features)), top_features[\"Feature\"])\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.title(\"Top 15 Most Important Features\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning (Optional)\n",
    "\n",
    "Use GridSearchCV to find optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search with 3-fold cross-validation\n",
    "xgb = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    xgb,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Running grid search (this may take several minutes)...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✓ Grid search complete\")\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV ROC-AUC: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "roc_auc_best = roc_auc_score(y_test, y_pred_proba_best)\n",
    "\n",
    "print(f\"\\nBest Model Test Performance:\")\n",
    "print(f\"  Accuracy: {accuracy_best:.2%}\")\n",
    "print(f\"  ROC-AUC: {roc_auc_best:.4f}\")\n",
    "\n",
    "# Update strategy with best model\n",
    "strategy.model = best_model\n",
    "print(\"\\n✓ Strategy updated with best model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model\n",
    "\n",
    "Save the trained model for use in backtesting and production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = \"models/xgboost_h2h_v1.pkl\"\n",
    "strategy.save_model(model_path)\n",
    "\n",
    "print(f\"✓ Model saved to {model_path}\")\n",
    "print(f\"\\nModel details:\")\n",
    "print(f\"  Features: {len(strategy.feature_names)}\")\n",
    "print(f\"  Training samples: {X_train.shape[0]}\")\n",
    "print(f\"  Test ROC-AUC: {roc_auc_best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Backtest the Strategy\n",
    "\n",
    "Test the trained model on a separate time period using the backtesting framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define backtest period (should be different from training period)\n",
    "BACKTEST_START = datetime(2024, 12, 1)\n",
    "BACKTEST_END = datetime(2024, 12, 31)\n",
    "\n",
    "# Load the saved model\n",
    "backtest_strategy = XGBoostStrategy(\n",
    "    model_path=model_path,\n",
    "    min_edge_threshold=0.03,  # Require 3% edge\n",
    "    min_confidence=0.52       # Only bet if model predicts >52% win probability\n",
    ")\n",
    "\n",
    "# Configure backtest\n",
    "config = BacktestConfig(\n",
    "    start_date=BACKTEST_START,\n",
    "    end_date=BACKTEST_END,\n",
    "    initial_bankroll=10000.0,\n",
    "    bet_sizing_method=\"fractional_kelly\",\n",
    "    kelly_fraction=0.25,  # Quarter-Kelly for safety\n",
    "    max_bet_percentage=0.05,\n",
    "    min_bet_size=10.0,\n",
    "    max_bet_size=500.0,\n",
    "    decision_hours_before_game=1\n",
    ")\n",
    "\n",
    "print(f\"Running backtest from {BACKTEST_START.date()} to {BACKTEST_END.date()}...\")\n",
    "\n",
    "# Run backtest\n",
    "async with get_async_session() as session:\n",
    "    reader = OddsReader(session)\n",
    "    engine = BacktestEngine(backtest_strategy, config, reader)\n",
    "    result = await engine.run()\n",
    "\n",
    "print(\"\\n✓ Backtest complete\")\n",
    "print(result.to_summary_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "result.to_json(\"backtest_results_xgboost.json\")\n",
    "result.to_csv(\"backtest_bets_xgboost.csv\")\n",
    "\n",
    "print(\"✓ Results saved\")\n",
    "print(f\"  JSON: backtest_results_xgboost.json\")\n",
    "print(f\"  CSV: backtest_bets_xgboost.csv\")\n",
    "\n",
    "# Plot equity curve\n",
    "equity_df = pd.DataFrame([\n",
    "    {\"date\": point.date, \"bankroll\": point.bankroll}\n",
    "    for point in result.equity_curve\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(equity_df[\"date\"], equity_df[\"bankroll\"], linewidth=2)\n",
    "plt.axhline(y=config.initial_bankroll, color=\"r\", linestyle=\"--\", alpha=0.5, label=\"Starting Bankroll\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Bankroll ($)\")\n",
    "plt.title(\"XGBoost Strategy - Equity Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Metrics:\")\n",
    "print(f\"  Total Bets: {result.total_bets}\")\n",
    "print(f\"  Win Rate: {result.win_rate:.2f}%\")\n",
    "print(f\"  ROI: {result.roi:.2f}%\")\n",
    "print(f\"  Total Profit: ${result.total_profit:,.2f}\")\n",
    "print(f\"  Sharpe Ratio: {result.sharpe_ratio:.2f}\")\n",
    "print(f\"  Max Drawdown: ${abs(result.max_drawdown):,.2f} ({result.max_drawdown_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Data Preparation**: Loading historical events with odds snapshots\n",
    "2. **Feature Engineering**: Extracting 15+ features capturing market dynamics\n",
    "3. **Model Training**: XGBoost classifier with hyperparameter tuning\n",
    "4. **Evaluation**: ROC-AUC, calibration, feature importance analysis\n",
    "5. **Backtesting**: Seamless integration with backtesting framework\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Improve Features**: Add more sophisticated features (e.g., team stats, injuries)\n",
    "- **Feature Selection**: Use recursive feature elimination to reduce overfitting\n",
    "- **Model Ensembles**: Combine XGBoost with other models (LightGBM, Neural Networks)\n",
    "- **Time-Series Validation**: Use walk-forward analysis instead of random split\n",
    "- **Spread/Totals Models**: Train separate models for spread and totals markets\n",
    "- **Production Deployment**: Integrate with live odds fetching for real-time predictions\n",
    "\n",
    "### Using This Pattern for Other Models\n",
    "\n",
    "This workflow can be adapted for:\n",
    "- **LightGBM**: Similar to XGBoost but potentially faster\n",
    "- **Neural Networks**: Use PyTorch/TensorFlow for deep learning\n",
    "- **Time Series Models**: LSTM/GRU for sequential line movement patterns\n",
    "- **Ensemble Methods**: Stack multiple models for better predictions\n",
    "\n",
    "See `analytics/ml_strategy_example.py` for implementation details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
